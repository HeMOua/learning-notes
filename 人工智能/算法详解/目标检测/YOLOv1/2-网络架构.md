# 网络架构

```python
def make_block(num_sample, in_channels, channels, mid_layer=None, pooling=True):
    layers = []
    # 卷积层
    for _ in range(num_sample):
        layers.append(nn.Conv2d(in_channels, channels[0], kernel_size=(1, 1)))
        layers.append(nn.LeakyReLU(0.1))
        layers.append(nn.Conv2d(channels[0], channels[1], kernel_size=(3, 3), padding=1))
        layers.append(nn.LeakyReLU(0.1))
        in_channels = channels[1]
    if mid_layer is None:
        layers.append(nn.Conv2d(channels[1], channels[1], kernel_size=(1, 1)))
        layers.append(nn.LeakyReLU(0.1))
        layers.append(nn.Conv2d(channels[1], channels[2], kernel_size=(3, 3), padding=1))
        layers.append(nn.LeakyReLU(0.1))
    else:
        for layer in mid_layer:
            layers.append(layer)
            layers.append(nn.LeakyReLU(0.1))
    # 池化层
    if pooling:
        layers.append(nn.MaxPool2d(kernel_size=2, stride=2))
    return nn.Sequential(*layers)

class YOLOv1(nn.Module):
    def __init__(self, in_channels=3):
        super(YOLOv1, self).__init__()
        # 第1层卷积
        self.block_1 = nn.Sequential(
            nn.Conv2d(in_channels, 64, kernel_size=(7, 7), stride=(2, 2), padding=3), nn.LeakyReLU(0.1),
            nn.MaxPool2d(2, stride=2)
        )
        # 第二层卷积
        self.block_2 = nn.Sequential(
            nn.Conv2d(64, 192, kernel_size=(3, 3), padding=1), nn.LeakyReLU(0.1),
            nn.MaxPool2d(2, stride=2)
        )
        # 第3~6层卷积
        self.block_3 = make_block(1, 192, (128, 256, 512))
        # 第7~16层卷积
        self.block_4 = make_block(4, 512, (256, 512, 1024))
        # 第17~22层卷积
        self.block_5 = make_block(2, 1024, (512, 1024), mid_layer=[
            nn.Conv2d(1024, 1024, kernel_size=(3, 3), padding=1), nn.LeakyReLU(0.1),
            nn.Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=1), nn.LeakyReLU(0.1)
        ], pooling=False)
        # 第23~24层卷积
        self.block_6 = make_block(0, None, None, mid_layer=[
            nn.Conv2d(1024, 1024, kernel_size=(3, 3), padding=1), nn.LeakyReLU(0.1),
            nn.Conv2d(1024, 1024, kernel_size=(3, 3), padding=1), nn.LeakyReLU(0.1)
        ], pooling=False)
        # 第1个全连接层
        self.fc_1 = nn.Sequential(
            nn.Flatten(),
            nn.Linear(1024 * 7 * 7, 4096), nn.LeakyReLU(0.1)
        )
        # 第2个全连接层
        self.fc_2 = nn.Sequential(
            nn.Dropout(),  # Dropout防止过拟合
            nn.Linear(4096, 30 * 7 * 7),
            nn.Sigmoid()
        )

    def forward(self, x):
        x = self.block_1(x)
        x = self.block_2(x)
        x = self.block_3(x)
        x = self.block_4(x)
        x = self.block_5(x)
        x = self.block_6(x)
        x = self.fc_1(x)
        x = self.fc_2(x)
        return x.view(-1, 7, 7, 30)
```

