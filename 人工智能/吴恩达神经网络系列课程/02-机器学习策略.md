# 机器学习策略

## 正交化

假如我们在搭建一个深度学习的项目，我们有众多方法来帮助我们提高模型能力，但是正确选择这个方法是十分重要的。

这里介绍一个关于正交化的概念，假如一辆汽车有4个旋钮，一个能调整方向，一个能调整速度，剩余的能同时调整方向和速度，但是如果让你选择旋钮的话，那一定不会选择后两个，尽管它们能做到同样的效果，但是过程往往更加费时费力。

在机器学习中，我们希望找到几个指标，修改它们就能对某一方向的内容产生明显变化，而不是对不同的内容都产生印象，如果是这样，我们希望能找到一个正交解，让其只能对某一方向上的东西产生影响

## 单一数字评估指标

假如有多个模型，我们要想办法从中选出一个性能、效果最佳的作为最终产品，这时我们就需要各种指标来判断哪个模型更好，但是有的模型在一个指标下表现较好，但在另一个指标下表现差，而有的模型恰恰与他相反，那么这时该如何选择模型呢？

我们需要一个单一数字的评估指标，假如有多个指标，我们可以将它们综合起来，最简单的一种方式就是求平均数，或者调和平均等等。

## 人的表现

通常是指人能达到的极限，贝叶斯错误率要比人类极限更小

+ 可避免偏差：训练集错误率 - 人类水平，如何减小差距
  + 训练更大的模型
  + 使用更好的优化算法，比如加入momentum、RMSprop或Adam
  + 选择更好的网络架构，或更改超参数
  + 等

+ 方差：开发集错误率 - 训练集错误率
  + 收集更多数据
  + 正则化
  + 选择更好的网络架构，或更改超参数
  + 等

## 误差分析

如果你希望让学习算法能够胜任人类能做的任务，但是你的学习算法还没有达到人类的表现，那么人工检查一下你的**算法犯的错误**，也许可以让你了解接下来应该做什么，这个过程称为错误分析。

首先收集一下，比如说100个错误标记图片的开发集例子，然后手动检查，一次只看一个看看，建立这样一个表格，**第一列表示这些错误图像的标号，中间若干列表示错误的诱因，最后一列，就对应你要评估的想法**。

在错误分析过程中，你就看看算法识别错误的开发集例子，如果你发现第一张识别错误的图片是狗图，那么就在那里打个勾，在评论里注释，也许这是一张比特犬的图，如果第二张照片很模糊，也注释记一下，以此类推，**最终统计那一列有多少百分比图像打了勾**，在这个步骤做到一半时，有时你可能会发现其他错误类型，比如说你可能发现有Instagram滤镜 那些花哨的图像滤镜，干扰了你的分类器，在这种情况下，实际上可以在**错误分析途中增加这样一列**。

但这个快速统计的步骤你可以经常做最多需要几小时，就可以真正帮助我们**选出高优先级任务**，并了解每种手段对性能有多大提升空间。

在做错误分析的时候，有时你会注意到开发集里有些样本被错误标记了，这时应该怎么做呢?，我们下一个视频来讨论

## 清楚标注错误的数据

在做错误分析的时候，有时你会注意到开发集里有些样本被错误标记了，这时应该怎么做呢?

事实证明，**深度学习算法对于训练集中的随机错误是相当健壮的**，只要你的标记出错的例子，只要错误足够随机，那么放着这些错误不管可能也没问题，而不要花太多时间修复它们，当然你浏览一下训练集，检查一下这些标签 并修正它们也没什么害处。

虽然深度学习算法对随机误差很健壮，但**对系统性的错误就没那么健壮**了，所以比如说如果做标记的人一直把白色的狗标记成猫，那就成问题了。

## 系统搭建方案

如果你想搭建全新的机器学习程序，就是**快速搭好你的第一个系统**然后开始迭代，快速设立开发集和测试集还有指标，这样就决定了你的目标所在，如果你的目标定错了之后改也是可以的，但一定要**设立某个目标**，然后我建议你马上搭好一个机器学习系统原型，然后找到训练集 训练一下看看效果，开始理解你的算法表现如何，在开发集测试集你的评估指标上表现如何。

当你建立第一个系统后，就可以马上**用到偏差方差分析，还有错误分析**，来确定**下一步优先做什么**，特别是如果错误分析，让你了解到大部分的错误的来源，然后想出所有能走的方向，哪些是实际上最有希望的方向，不过如果你在这个应用程序领域有很多经验，这个建议适用程度要低一些。

还有一种情况适应程度更低，当这个领域，**有很多可以借鉴的学术文献**，处理的问题和你要解决的几乎完全相同，比如说人脸识别就有很多学术文献，如果你尝试搭建一个人脸识别设备，那么**可以从现有大量学术文献为基础出发**，一开始就**搭建比较复杂的系统**。

## 在不同的划分上进行训练并测试

**问题：**

假设你在开发一个手机应用，用户会上传，他们用手机拍摄的照片，你想识别用户从应用中上传的图片是不是猫，现在你有两个数据来源。

一个是你真正关心的数据分布来自应用上传的数据，比这些照片一般更业余，取景不太好，有些甚至很模糊，因为它们都是业余用户拍的。

另一个数据来源就是你可以用爬虫程序挖掘网页直接下载，就这个例子而言可以下载很多，取景专业 高分辨率拍摄专业的猫图片。

如果你的应用用户数还不多，也许你只收集到10,000张用户上传的照片，但通过爬虫挖掘网页你可以下载到海量猫图，也许你从互联网上下载了超过20万张猫图，而你真正关心的算法表现是你的最终系统，处理来自应用程序的这个图片分布时效果好不好。

**难点：**

现在你就陷入困境了，因为你有一个相对小的数据集，只有10,000个样本来自那个分布，而你还有一个**大得多的数据集**来自另一个分布，图片的外观和你真正想要处理的并不一样，但你又不想直接用这10,000张图片，因为这样，你的训练集就太小了，使用这20万张图片似乎有帮助但是，困境在于这20万张图片并不完全来自你想要的分布，那么你可以怎么做呢?

**解决方法：**

方法一：

这里有一种选择，将**两组数据合并在一起**，这样你就有21万张照片，你可以把这21万张照片，**随机分配到训练开发和测试集**中，为了说明观点，我们假设，你已经确定开发集和测试集各包含2500个样本，所以你的训练集有205000个样本，现在这么设立你的数据集有一些好处也有坏处。

**好处**在于你的训练集 开发集和测试集，都来自同一分布这样更好管理。但**坏处**在于，开发集会把大部分精力花费在处理网页上的数据，而不是用户所上传的，与我们的想法背道而驰。

方法二：

训练集是来自网页下载的200,000张图片，然后如果需要的话再加上5000张来自手机上传的图片，然后对于开发集和测试集，这数据集的大小不是按比例画的，你的**开发集和测试集都是手机图**，而**训练集包含了来自网页的20万张图片，还有5000张来自应用的图片**，开发集就是2500张来自应用的图片，测试集也是2500张来自应用的图片。

这样**将数据分成训练集、开发集和测试集**的好处在于，现在你瞄准的目标就是你想要处理的目标，你告诉你的团队 我的开发集包含的数据全部来自手机上传，这是你真正关心的图片分布，这能带来长期更好的系统性能。

## 迁移学习

深度学习中最强大的理念之一就是 有的时候 ，神经网络可以从一个任务中习得知识，并将这些知识应用到另一个独立的任务中，所以例如 也许你已经训练好一个神经网络，能够识别像猫这样的对象，然后使用，那些知识或者部分习得的知识，去帮助您更好地阅读x射线扫描图，这就是所谓的迁移学习。

什么时候迁移学习是有意义的？

+ 当任务A和任务B都**有同样的输入x**，并想**从任务A学习，并迁移一些知识到任务B**时
+ 当任务A的数据比任务B**多得多**时
+ 任务A的**低层次特征**，可以帮助任务B的学习

所以总结一下迁移学习最有用的场合是，如果你尝试优化任务B的性能，通常这个任务数据相对较少，在这种情况下你可能会找一个相关但不同的任务，如图像识别，其中你可能用1百万张图片训练过了，并从中学到很多低层次特征，所以那也许能帮助网络在任务B 上做得更好，尽管任务B没有这么多数据。

## 多任务学习

在迁移学习中你的步骤是串行的，你从任务A里学到知识，然后迁移到任务B，在多任务学习中你是同时开始学习的，试图让**单个神经网络**同时做几件事情，然后希望这里每个任务都能**帮到其他所有任务**。

那么多任务学习什么时候有意义呢？当三件事为真时它就是有意义的

+ 可以共用低层次特征
+ 每个任务的数据量很接近（不是那么绝对）
  + 比如说你要完成100个任务，而你要做多任务学习，尝试同时识别100种不同类型的物体，你可能会发现每个任务大概有1000个样本
  + 所以如果你专注加强单个任务的性能，比如我们专注加强第100个任务的表现，我们用A100表示，如果你试图单独去做这个最后的任务，你只有1000个样本去训练这个任务
  + 这是100项任务之一，而通过在其他99项任务的训练，这些加起来可以一共有99000个样本 这可能大幅提升算法性能，可以提供很多知识来增强这个任务的性能
+ 当可以训练一个足够大的神经网络，同时做好所有的工作

目前迁移学习比多任务学习使用更多

## 端到端的深度学习

深度学习中最令人振奋的最新动态之一 ，就是端到端深度学习的兴起，那么端到端学习到底是什么呢？简而言之以前有一些数据处理系统，或者学习系统它们需要**多个阶段的处理**，那么端到端深度学习，就是忽略所有这些不同的阶段，用**单个神经网络代替**它。

**优点**

+ 让数据说话
+ 所需手工设计的组件更少，所以这也许能够简化你的设计工作流程，你不需要花太多时间去手工设计功能

**缺点**

+ 需要大量的数据，要直接学到这个x到y的映射，可能需要大量x,y数据
+ 它排除了可能有用的手工设计组件
  + 虽然机器学习研究人员一般都很鄙视手工设计的东西，但如果你没有很多数据，你的学习算法，就没办法从很小的训练集数据中获得洞察力

决定是否使用端到端深度学习的关键的问题是，你是否有足够的数据，能够直接学到从x映射到y上足够复杂的函数?

